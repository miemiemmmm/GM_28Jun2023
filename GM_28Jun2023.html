<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8" />
    <title>Group Meeting 28 June 2023</title>
    <script type="module">
        // Load the three.js for 3d object visualization
        import * as THREE from  "https://cdn.jsdelivr.net/npm/three@0.127.0/build/three.module.js"
        import { OrbitControls } from "https://cdn.jsdelivr.net/npm/three@0.127.0/examples/jsm/controls/OrbitControls.js"
        import { PLYLoader } from "https://cdn.jsdelivr.net/npm/three@0.127.0/examples/jsm/loaders/PLYLoader.js"
        window.THREE = THREE;
        window.OrbitControls = OrbitControls;
        window.PLYLoader = PLYLoader
    </script>

    <!-- Load reveal.js -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/reveal.js/3.6.0/css/reveal.min.css" integrity="sha512-V5fKCVKOFy36w8zJmLzPH5R6zU6KvuHOvxfMRczx2ZeqTjKRGSBO9yiZjCKEJS3n6EmENwrH/xvSwXqxje+VVA==" crossorigin="anonymous" referrerpolicy="no-referrer" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/reveal.js/3.6.0/js/reveal.min.js" integrity="sha512-QYXU3Cojl94ZRiZRjUZpyg1odj9mKTON9MsTMzGNx/L3JqvMA3BQNraZwsZ83UeisO+QMVfFa83SyuYYJzR9hw==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>

    <!-- Load jQuery-->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/1.9.1/jquery.min.js" integrity="sha512-jGR1T3dQerLCSm/IGEGbndPwzszJBlKQ5Br9vuB0Pw2iyxOy+7AK+lJcCC8eaXyz/9du+bkCy4HXxByhxkHf+w==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>

    <!-- Load 3DMol.js -->
    <script src="https://3Dmol.org/build/3Dmol-min.js"></script>
    <script src="https://3Dmol.org/build/3Dmol.ui-min.js"></script>

    <!-- Load MathJax for labex representation -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js?config=TeX-AMS_HTML"></script>

    <style>
        body {
            margin: 0;
        }

        section {
            position: absolute !important;
            top:0  !important;
            left:0  !important;
            height: 100%  !important;
            /*width: 100%  !important;*/
        }
        canvas {
            display: block;
        }

        .presentation_title {
            position: absolute !important;
            font-size: 45px !important;
            font-weight: bold !important;
            line-height: 1.25 !important;
            padding-bottom: 20px !important;
        }
        .presentation_title2 {
            padding-right: 50px !important;
            line-height: 1.25 !important;
            padding-bottom: 15px !important;
            text-align: right !important;
            font-size: 20px !important;
        }

        .page-number {
            position: absolute;
            bottom: 35px;
            right: 8%;
            color: black;
            font-size: 36px;
        }
        .uzh_logo{
            position: absolute !important;
            top: 2.5vh !important;
            left: 2.5vw !important;
            height: 10vh;
            width: auto;
        }
        .symbol_fig{
            position: absolute;
            top: 2.5vh;
            right: 2.5vw;
            height: 10vh;
            /*filter: blur(2px); */
        }

        .reveal .progress{
            height: 8px !important;
            background-color: #F3E99F !important;
        }
        .reveal .progress span {
            background-color: #FF6D60 !important;
            transition: width 0.5s ease-out !important;
            opacity: 1 !important;
            z-index: 0 !important;
        }
        .laser-pointer {
            position: absolute;
            width: 20px;
            height: 20px;
            background-color: red;
            border-radius: 50%;
            opacity: 0;
            pointer-events: none;
            z-index: 1000;
            transition: opacity 0.3s;
        }

    </style>

    <style>
        .slide-title {
            position: absolute !important;
            top: 12.5% !important;
            left: 2.5% !important;
            padding: 10px !important;
            font-size: 25px !important;
            font-weight: bold !important;
            z-index:auto !important;
        }

        /* Left text and right figure style pair*/
        .slide_content_style1{
            position: absolute !important;
            top: 20% !important;
            left: 2.5% !important;
            width: 45% !important;
            padding: 10px !important;
            font-size: 20px !important;
            text-align: left !important;
        }
        .slide_item_style1{
            padding-bottom: 20px  !important;
            font-size: 20px  !important;
        }
        .image-style1{
            position: absolute !important;
            top: 20% !important;
            left: 50% !important;
            width: 50% !important;
            height: 65% !important;
        }
        .tablecell_style1{
            font-size: 15px !important;
        }
        .highlight_style1{
            color: darkred !important;
            font-size: 25px !important;
            padding-top: 15px !important;
            padding-bottom: 15px !important;
            font-weight: bold !important;
        }
        .image-style2{
            position: absolute !important;
            top: 60% !important;
            /*left: 50% !important;*/
			width: 100% !important;
        }


        .caption_style{
            font-size: 15px !important;
            position: relative;
            /*display: block;*/
            width:50% !important;
        }

        .reference_style{
            position: absolute !important;
            bottom: 8% !important;
            left: 0 !important;
            color: rgb(108, 108, 108) !important;
            font-size: 8px !important;
            width:80%;
            text-align: left;
        }

        .mol-container{
            position: relative !important;
            padding-top: 100%;
        }
        .content_subtitle{
            background: #e6f0b680 !important;
			font-size: 15px !important;
            padding: 5px !important;
            margin-top: 10px !important;
            margin-bottom: 20px !important;
            background: radial-gradient(circle at center, #e6f0b680, #e6f0b630) !important;
            border-radius: 10px !important;
            background-color: #e6f0b680 !important;
        }

        .mol-container canvas {
            position: absolute !important;
            top: 0 !important;
            bottom: 0 !important;
            left: 0 !important;
            right: 0 !important;
            padding: 0 !important;
        }

        ul li{
            padding-bottom:10px !important;
            font-size: 25px !important;
        }

        .chapter_break{
            position: absolute !important;
            top : 50% !important;
            left: 50% !important;
            width:100% !important;
            font-size: 45px !important;
            font-weight: bold !important;
            line-height: 1.25 !important;
            transform: translate(-50%, -50%) !important
        }

        .image-gray {
            filter: grayscale(100%);
        }

    </style>

    <style>
        .gallery {
            position: relative;
            display: flex;
            flex-wrap: wrap;
            justify-content: center;
            align-items: center;
        }

        .gallery-item {
            position: relative !important;
            margin-right: 40px !important;
            margin-left: 40px !important;
            margin-top: 20px !important;
            margin-bottom:50px !important;
        }

        .gallery-item img {
            width: auto;
            height: 150px;
            transition: all 0.3s ease-out;
        }

        .gallery-item:hover img {
            transform: scale(3);
        }
        .gallery-item_style2:hover img {
            transform: scale(1.5) !important;
        }
        .gallery-item_style3:hover img {
            transform: scale(2) translateY(20%) translateX(20%) !important;
        }
        .gallery-item_style4:hover img {
            transform: scale(2) translateX(-10%) !important;
        }

        .gallery-item figcaption {
            position: absolute;
            bottom: -20px;
            left: 0;
            width: 100%;
            text-align: center;
            border-radius: 10px;
            background-color: #fff0dbd0;
            padding: 10px;
            transform: translateY(100%);
            transition: transform 0.3s ease-out;
        }

        .gallery-item:hover figcaption {
            transform: translateY(170px);
        }
    </style>

</head>
<body>
<div class="reveal">
    <div class="laser-pointer"></div>
    <div class="slides" id="slide_container">
        <!-- Title page -->
        <section data-state="Title_Page">
            <img id="greeting_bgimage" src="/interval_background.png" style="position: absolute; top:10px; right:-300px; opacity:0.25; transform: rotate(-30deg); filter: blur(2px); height: 700px; width: auto;">
            <div style="position:relative; height:300px; width:100%; top:5%"><p class="presentation_title" style="top:50px; width:100%">Improving molecular interaction recognition with molecular dynamics</p></div>
            <p class="presentation_title2">Yang Zhang</p>
            <p class="presentation_title2">Caflisch group Meeting</p>
            <p class="presentation_title2">28 June, 2023</p>
        </section>

        <!--Template page-->
        <!--<section data-state="slide_">-->
        <!--    <p class="slide-title">This is a Template Slide for Demonstration</p>-->
        <!--    <div class="slide_content_style1">-->
        <!--        <p>This is a Template Main Context1</p>-->
        <!--        <p>This is a Template Main Context2</p>-->
        <!--        <p>This is a Template Main Context3</p>-->
        <!--    </div>-->
        <!--    <p class="reference_style">This is a template reference.</p>-->
        <!--</section>-->

        <section data-state="slide_OutlinePage">
            <p class="slide-title">Outline</p>
            <div class="slide_content_style1" style="width: 100% !important;">
                <p class="slide_item_style1" style="padding-left: 10%; ">1. Introduction </p>
                <p class="slide_item_style1" style="padding-left: 10%; ">2. Current methods: binding affintiy prediction </p>
				<p class="slide_item_style1" style="padding-left: 10%; ">3. Data-driven method to re-construct the binding pocket landscape </p>
                <p class="slide_item_style1" style="padding-left: 10%; ">4. Augmenting prediction with molecular dynamics data </p>
                <p class="slide_item_style1" style="padding-left: 10%; ">5. Progress and future work </p>
            </div>

            <div class="image-style1">
                <img id="outline_bgimage" src="/interval_background.png" style="position: absolute; top:10px; right:-300px; opacity:0.25; transform: rotate(-30deg); height: 700px; width: auto; filter: blur(5px);" >
            </div>
        </section>

		<section data-state="">
			<div class="chapter_break_container">
				<p class="chapter_break">Current methods: binding affintiy prediction</p>
				<img title="Needed for the ">
			</div>
		</section>

        <section data-state="slide_VoxelBasedMethod">
			<p class="slide-title">Current methods: Graph and 3D voxel methods</p>
			<div class="slide_content_style1">
				<table>
					<tr>
						<th class="content_subtitle" style="background: radial-gradient(circle at center, #95E1D380, #95E1D330) !important; width:50%; text-align: center">Pros</th>
						<th class="content_subtitle" style="background: radial-gradient(circle at center, #F3818180, #F3818130) !important; width:50%; text-align: center">Cons</th>
					</tr>
					<tr ><td class="content_subtitle" colspan="2">Graph-based method</td></tr>
					<tr>
						<td style="padding-left:15px; height: 90px; background: radial-gradient(circle at center, #95E1D380, #95E1D330) !important">
							<ul>
								<li class="tablecell_style1">Invariance to rotation and translation</li>
								<li class="tablecell_style1">Lower computational cost</li>
								<li class="tablecell_style1">Greater scalability and interpretability</li>
							</ul>
						</td>
						<td style="padding-left:15px; height: 90px; background: radial-gradient(circle at center, #F3818180, #F3818130) !important">
							<ul>
								<li class="tablecell_style1">Loss of precise spatial relationships</li>
								<li class="tablecell_style1">Difficulty handling conformational changes</li>
								<li class="tablecell_style1">Limited representation of molecular properties</li>
							</ul>
						</td>
					</tr>

					<tr><td class="content_subtitle" colspan="2">Voxel-based method</tr>
					<tr>
						<td style="padding-left:15px; height: 90px; background: radial-gradient(circle at center, #95E1D380, #95E1D330) !important">
							<ul>
								<li class="tablecell_style1">Straight-forward and intuitive structural representation</li>
								<li class="tablecell_style1">Retains spatial configuration</li>
								<li class="tablecell_style1">Incorporates multiple molecular properties</li>
								<li class="tablecell_style1">Fine control over structural resolution</li>
							</ul>
						</td>
						<td style="padding-left:15px; height: 90px; background: radial-gradient(circle at center, #F3818180, #F3818130) !important">
							<ul>
								<li class="tablecell_style1">Sensitive to rotation and translation</li>
								<li class="tablecell_style1">High computational complexity</li>
								<li class="tablecell_style1">High demand for memory capacity</li>
							</ul>
						</td>
					</tr>
				</table>
				<p class="highlight_style1">The degree of complexity of molecular patterns needs to be reduced</p>
			</div>
			<div  class="image-style1">
				<img id="graphexample_img" src="/Example_GraphBasedMethod.png" style="height:40% !important"><br>
				<p for="graphexample_img" class="content_subtitle">Fig1: Example graph-based method</p><br>
				<img id="voxelexample_img" src="/Example_VoxelBasedMethod.png" style="height:40% !important; "><br>
				<p for="voxelexample_img" class="content_subtitle">Fig2: Example voxel-based method</p>
			</div>
			<p class="reference_style">
				Ragoza, Matthew, et al. "Protein–ligand scoring with convolutional neural networks." Journal of chemical information and modeling 57.4 (2017): 942-957.<br>
				Duvenaud, David K., et al. "Convolutional networks on graphs for learning molecular fingerprints." Advances in neural information processing systems 28 (2015).<br>
				Li, Yanjun, et al. "DeepAtom: A framework for protein-ligand binding affinity prediction." 2019 IEEE International Conference on Bioinformatics and Biomedicine (BIBM). IEEE, 2019.
			</p>
		</section>

		<section data-state="slide_">
            <p class="slide-title">Current methods: MD simulation in machine learning </p>
            <div class="slide_content_style1">
				<img src="/current_MD_method1.png" style="width:100% !important; ">
                <p class="content_subtitle" style="width:100% !important; padding-bottom: 30px">Method1: Encode the atoms with their 2D descriptor and 3D descriptor of trajectory</p>
				<img src="/current_MD_method3.png" style="width:100% !important; ">
				<p class="content_subtitle" style="width:100% !important;">Method2: For each atom, encode their potential energy \(E_{i}\) with neural network </p>

            </div>
			<div  class="image-style1">
				<img  src="/current_MD_method2.png" style="width:100% !important; ">
				<p class="content_subtitle" style="width:100% !important;">Method3: Encode the 3D coordinate of atoms to RGB chennels of 2D images</p>
			</div>
            <p class="reference_style">
				Ash, Jeremy, and Denis Fourches. "Characterizing the chemical space of ERK2 kinase inhibitors using descriptors computed from molecular dynamics trajectories." Journal of chemical information and modeling 57.6 (2017): 1286-1299.<br>
				Gastegger, Michael, Jörg Behler, and Philipp Marquetand. "Machine learning molecular dynamics for the simulation of infrared spectra." Chemical science 8.10 (2017): 6924-6935.<br>
				Plante, Ambrose, et al. "A machine learning approach for the discovery of ligand-specific functional mechanisms of GPCRs." Molecules 24.11 (2019): 2097.
			</p>
        </section>

		<section data-state="slide_">
            <p class="slide-title">3D voxel-based binding affintiy prediction</p>
            <div class="slide_content_style1">
                <p class="slide_item_style1">Training set: PDBBind-refined set is used as high quality training dataset and test set</p>
				<p class="slide_item_style1">Learning method: 3D convolutional neural network</p>
				<p class="slide_item_style1">Feature engineering: Both simple and complex features are used differently</p>
				<p class="slide_item_style1">Feature engineering: Different combinations/arrangement of features</p>

				<p class="slide_item_style1">Predicted results are biased  </p>
            </div>
			<div  class="image-style1">
				<img  src="/pafnucy_input.jpeg" style="height:40% !important; "><br>
				<p class="content_subtitle">Fig1. Input tensor represented with a 4D tensor in pafnucy</p>
				<img  src="/gnina_atomdensity.jpeg" style="height:40% !important; ">
				<p class="content_subtitle">Fig2. Visualization of atom densities used as input to CNN scoring for Gnina</p>
			</div>
            <p class="reference_style">
				Stepniewska-Dziubinska, Marta M., Piotr Zielenkiewicz, and Pawel Siedlecki. "Development and evaluation of a deep learning model for protein–ligand binding affinity prediction." Bioinformatics 34.21 (2018): 3666-3674.<br>
				Ragoza, Matthew, et al. "Protein–ligand scoring with convolutional neural networks." Journal of chemical information and modeling 57.4 (2017): 942-957.
			</p>
        </section>



		<section data-state="slide_common_methods">
			<p class="slide-title">Kep hypothesis for 3D-based affinity prediction software</p>
			<div class="slide_content_style1">
				<p class="slide_item_style1">1. Ligand binding is primarily determined by the local atomic configurations</p>
				<p class="slide_item_style1">2. Substructure reduces structural complexity of the binding pocket </p>
				<p class="slide_item_style1">3. Molecular properties are able to be mapped to 3D voxels</p>
				<p class="slide_item_style1">4. Various atomic/molecular properties helps neural network prediction</p>
				<p class="content_subtitle"><span class="highlight_style1" style="line-height: 40px">Objective: </span><br><span class="slide_item_style1" style="margin-bottom: 10px">Develop a framework to preprocess molecular dynamics trajectories and prepare input data for voxel-based binding affinity prediction.</span><br> </p>
			</div>

			<div style="position: absolute; top:20%; left:50%; width:450px !important; height: 450px !important">
				<div id="slide_RefPDBAndBox" style="width: 100%; height: 100%"></div>
				<p class="content_subtitle" style="font-size: 12px"><span style="font-weight: bold;">Stage1:</span> Protein(gray cartoon); ligand and pocket(green sticks), bounding box(light green cuboid), grid points(red dots) and molecule blocks (purple cuboids)</p>
			</div>
		</section>





		<section data-state="slide_">
            <p class="slide-title">Imporve 3D-based affinity prediction with protein dynamics??? </p>
            <div class="slide_content_style1">
                <p class="slide_item_style1">1. Protein is flexible in natural condition</p>
                <p class="slide_item_style1">2. Small conformational change could lead to significant change in 3D features</p>
                <p class="slide_item_style1">3. Molecular dynamics simulation provides a interface to study the protein flexibility and solvent effect</p>
				<p class="slide_item_style1">4. This map enables predictions for static configurations via the detour of predicting dynamic features</p>
            </div>
            <p class="reference_style">This is a template reference.</p>
        </section>

		<section data-state="">
			<div class="chapter_break_container">
				<p class="chapter_break">Data-driven method to re-construct the binding pocket landscape</p>
				<img title="Needed for the ">
			</div>
		</section>


		<section data-state="slide_PackageArchetecture">
			<p class="slide-title">Feature database construction </p>
			<!--Attach the representation of the Package Archetecture-->
			<div class="gallery" style="top:30% !important;">
				<figure class="gallery-item PackageArchetecture image-gray">
					<img id="PackageArchetecture_fig1" style="height: 200px !important; " src="/MD_workflow_2.png">
					<figcaption for="PackageArchetecture_fig1">Fig1: Batch MD simulation using the ACGui</figcaption>
				</figure>
				<figure class="gallery-item PackageArchetecture image-gray">
					<img id="PackageArchetecture_fig2" src="/Step1_2_Trajectory_processing_pipeline.jpg">
					<figcaption for="PackageArchetecture_fig2">Fig2: Automated pipeline for trajectory decomposition</figcaption>
				</figure>
				<figure class="gallery-item PackageArchetecture image-gray">
					<img id="PackageArchetecture_fig3" src="/Step1_3_Example_feature_block.png">
					<figcaption for="PackageArchetecture_fig3">Fig3: Feature generation, representation, and storage</figcaption>
				</figure>
			</div>
		</section>

		<section data-state="slide_TrajectoryPreparation">
			<p class="slide-title">Training material (Trajectory) generation </p>
			<div class="slide_content_style1">
				<p class="slide_item_style1">1. ACGui batch MD simulation is used for standard simulation system preparation </p>
				<p class="slide_item_style1">2. Protein-ligand complexes are sourced from the PDBBind refined set</p>
				<p class="slide_item_style1">3. In the first batch of simulations, 75 pairs of complexes are simulated 4 times for 50ns per run</p>
				<p class="slide_item_style1">4. Sequence embedding is applied to eliminate protein redundancy </p>
			</div>

			<div class="image-style1">
				<figure class="gallery-item gallery-item_style2" style="width: 100% !important; ">
					<img id="traj_prep" src="/MD_workflow_2.png" style="width: 100% !important; height: auto;">
					<figcaption class="content_subtitle" for="traj_prep">Fig. Workflow of the ACGui batch MD simulation. </figcaption>
				</figure>
			</div>
			<p class="reference_style">Ranjan, Chitta, Samaneh Ebrahimi, and Kamran Paynabar. "Sequence graph transform (SGT): A feature embedding function for sequence data mining." arXiv preprint arXiv:1608.03533 (2016).</p>
		</section>

		<section data-state="slide_ExampleMolBlock">
			<p class="slide-title">Segmenting a molecule block </p>
			<!--Example image of a molecule block (box) as well as protein structure -->
			<div class="slide_content_style1">
				<p class="slide_item_style1">1. Each molecule block is segmented by consecutive residues, top 6 segments are retained</p>
				<p class="slide_item_style1">2. Atoms from consecutive residues (within N residues) are considered to be in one segment </p>
				<p class="slide_item_style1">3. For the computation of chemical features, full residues are maintained if at least one atom falls into the bounding box (Stage1)</p>
				<p class="slide_item_style1">4. Segments are ordered from the most atoms to the least atoms (Stage2)</p>
				<p class="slide_item_style1">5. Each segment computes multiple types of descriptors (topological, chemical and geometric) </p>

			</div>
			<div class="image-style1" style="top:10% !important; ">
				<div id="mol_block_pdb" class="mol-container" style="left: 50% !important; transform: translate(-50%) !important;  height: 200px !important; width: 100% !important;"></div>
				<p for="mol_block_pdb" class="content_subtitle" style="margin-top: 10px !important; position: relative; text-align: left !important; ">Stage1: Example of a "molecule block" shown in stick representation, with the bounding box colored purple. </p><br>
				<div id="mol_block_mesh" style="height: 200px !important; width: 100% !important; position: relative; left: 50% !important; transform: translate(-50%) !important; "></div>
				<p for="mol_block_mesh" class="content_subtitle" style="margin-top: 10px !important; position: relative; text-align: left !important; ">Stage2: Visualization of the segmented "molecule block" as a triangular mesh. Segments are arranged in a gradient from dark to bright colors, indicating their order. </p>
			</div>
		</section>

		<section data-state="slide_Intro3DInterpolation">
			<p class="slide-title">Feature interpolation from coordinates to mesh grids</p>
			<!--Attach the function to interpolate and the method to distribute features -->
			<div class="slide_content_style1">
				<p class="slide_item_style1">1. Initialize a grid on top of each molecule block and create a Kd-tree for neighbor search</p>
				<p class="slide_item_style1">2. Select a coordinate and query the grid point within a specified distance</p>
				<p class="slide_item_style1">3. Rasterize the "weight" of the coordinate (e.g. atomic mass) using Gaussian: <br><span style="padding-left:100px">\(w_i = \frac{w_0}{\sigma \sqrt{2\pi}}exp\left(-\frac{\left(r_i-r_0\right)^2}{\sigma^2}\right)\)</span> </p>
				<p class="slide_item_style1" style="padding-left: 20px !important; ">where \(r_i\) is the grid point coordinate and the \(r_0\) is the reference atom coordinate, \(w_0\) is the feature weight of that atom, and \(\sigma\) is the smoothness of the interpolation </p>
				<p class="slide_item_style1">4. Repeat steps 2 and 3 until all atoms in the bounding box are processed </p>
			</div>
			<div class="image-style1">
				<img id="feature_interp_exp1" src="/tmp05dodkbp_final_feat.png" style="height: 36%">
				<img id="feature_struct_exp1" src="/tmp05dodkbp_final_conf.png" style="height: 36%">
				<p class="content_subtitle">Fig1: Example structure 1 within bounding box (right) and its rasterized features (left); Grid points are sized according to the cumulative weight of atom numbers. Residues are depicted with gold sticks, and the bounding box is colored pink.</p>
				<img id="feature_interp_exp2" src="/tmpo_gbx3oc_final_feat.png" style="height: 36%">
				<img id="feature_struct_exp2" src="/tmpo_gbx3oc_final_conf.png" style="height: 36%">
				<p class="content_subtitle">Fig2: Example structure 2 within bounding box (right) and its rasterized features (left); Color scheme is as the previous figure. </p>
			</div>
		</section>

		<section data-state="slide_RepresentingMolBlock">
			<p class="slide-title">Molecule block embedding</p>
			<!-- Attach a picture of several residues inside a box -->
			<div class="slide_content_style1">
				<p class="slide_item_style1">1. Topological, chemical, and geometric features are concatenated to represent a single segment</p>
				<p class="slide_item_style1">2. The molecular surface is computed to obtain the geometric feature of each segment</p>
				<p class="slide_item_style1">3. Each segment's triangle mesh is down-sampled to ~600 points and point cloud is saved for further registration</p>
				<p class="slide_item_style1">4. Join viewpoint components (VFH algorithm, will discuss later) to register the relative positions between segments</p>
<!--					<p class="slide_item_style1">4. The feature vectors of each segment are ultimately joined by their "relative position" features</p>-->
			</div>

			<div class="image-style1" style="width: 50%" >
				<table style="text-align: left; width: 100%; ">
					<tbody style="font-size: 15px">
					<tr><th class="content_subtitle" style="font-weight: bold; ">Topological feature</th></tr>
					<tr><td style="padding-bottom: 5px">Atom number</td></tr>
					<tr><td style="padding-bottom: 5px">Carbon Number</td></tr>
					<tr><td style="padding-bottom: 5px">Hydrogen Number</td></tr>
					<tr><td style="padding-bottom: 5px">Nitrogen number</td></tr>
					<tr><td style="padding-bottom: 5px">Oxygen Number</td></tr>
					<tr><td style="padding-bottom: 5px">Pseudo LJ: \(E_{lj} = 4 * \epsilon * ((\frac{\sigma}{r})^{12} - (\frac{\sigma}{r})^{6})\)</td></tr>
					<tr><td style="padding-bottom: 5px">Pseudo Elec: \(E_{el} = k*\frac{q_{1}*q_{2}}{r}\)</td></tr>
					<tr><th class="content_subtitle" style="font-weight: bold; ">Chemical feature</th></tr>
					<tr><td style="padding-bottom: 5px">Donor number: SMARTS search</td></tr>
					<tr><td style="padding-bottom: 5px">Acceptor number: SMARTS search</td></tr>
					<tr><td style="padding-bottom: 5px">Positive charge: Gasteiger algorithm</td></tr>
					<tr><td style="padding-bottom: 5px">Negative charge: Gasteiger algorithm</td></tr>
					<tr><th class="content_subtitle" style="font-weight: bold; ">Geometric feature</th></tr>
					<tr><td style="padding-bottom: 5px">Surface Area</td></tr>
					<tr><td style="padding-bottom: 5px">Occupied Volume</td></tr>
					<tr><td style="padding-bottom: 5px">Mean radius</td></tr>
					<tr><td style="padding-bottom: 5px">Convex hull</td></tr>
					</tbody>
				</table>
				<p class="" style="font-weight: bold">Table1: Available features </p>
			</div>
			<p class="reference_style">Sanner, M. F., Olson A.J. & Spehner, J.-C. (1996). Reduced Surface: An Efficient Way to Compute Molecular Surfaces. Biopolymers 38:305-320.</p>
		</section>

		<section data-state="slide_">
            <p class="slide-title">Combine the structural features with geometric features</p>
            <div class="slide_content_style1">
				<p class="slide_item_style1 highlight_style1" style="margin-bottom: 10px !important; ">Robust and specific substructure fingerprint for similarity computaiton </p>
                <p class="slide_item_style1">Viewpoint Feature Histogram (VFH) is suitable for object recognition and pose identification</p>
                <p>This is a Template Main Context2</p>
                <p>This is a Template Main Context3</p>
            </div>

			<div class="image-style1">
				<img src="/Viewpoint_Segments.jpg" alt="" style="height: 50% !important; ">
				<p class="content_subtitle">Fig1. Schematic 2D representation of viewpoint component and segmentation </p>
			</div>
			<div class="image-style2">
				<img src="/VFH_sig.png" alt="" style="width:75% !important; ">
				<p class="content_subtitle">Fig2. Viewpoint Feature Histogram (VFH) signatures of two different poses</p>
			</div>
        </section>

		<section data-state="slide_">
            <p class="slide-title">Computation of structural similarity from fingerprint</p>
            <div class="slide_content_style1">
				<p class="slide_item_style1 highlight_style1" style="margin-bottom: 10px !important; ">
					Require a robust metric to measure the similarity between two molecule blocks
				</p>
				<p class="slide_item_style1">Each box contains 6 segments in maximum and similarity is calculated by: </p>
                <p class="slide_item_style1" style="text-align: center !important; ">
					\( S=\frac{ \sum_{i=0}^{N} (C_{i} \times w_{i})}{\sum_{i=0}^{N}w_{i}}  \)
				</p>
				<p class="slide_item_style1">where \(w_{i}\) is the weight of the segment \(i\),</p>
				<p class="slide_item_style1">\( C_{i} \) is the cosine similarity between the test segment i and the target segment i:</p>
				<p class="slide_item_style1" style="text-align: center !important; ">
					\(C_{i}=\frac{V_{i} \cdot V_{target_i}}{\left \|V_{i} \right \| \ \left\|V_{target_i}\right\|}\)
				</p>
				<!--S=\frac{ \sum_{i=0}^{N} (C_{i} \times w_{i})}{\sum_{i=0}^{N}w_{i}}  -->
				<!--C_{i}=\frac{V_{i} \cdot V_{target}}{\left \|V_{i} \right \| \ \left\|V_{target}\right\|}-->
            </div>
			<div class="image-style1">
				<img style="height:80%  !important;; width: auto !important; height:auto" src="/cosine_similarity.jpg">
				<p class="content_subtitle">Fig. A paradigm for cosine similarity computation</p>
			</div>
            <p class="reference_style">https://en.wikipedia.org/wiki/Cosine_similarity<br>https://aitechtrend.com/how-cosine-similarity-can-improve-your-machine-learning-models/</p>
        </section>

        <!--<section data-state="slide_">-->
        <!--    <p class="slide-title">This is a Template Slide for Demonstration</p>-->
        <!--    <div class="slide_content_style1">-->
        <!--        <p>This is a Template Main Context1</p>-->
        <!--        <p>This is a Template Main Context2</p>-->
        <!--        <p>This is a Template Main Context3</p>-->
        <!--    </div>-->
        <!--    <p class="reference_style">This is a template reference.</p>-->
        <!--</section>-->

		<section data-state="">
			<div class="chapter_break_container">
				<p class="chapter_break">Augmenting prediction with molecular dynamics data</p>
				<img title="Needed for the ">
			</div>
		</section>

		<section data-state="slide_">
			<!--Page 17-->
            <p class="slide-title">Binding affinity data augmentation workflow</p>
            <div class="slide_content_style1">
                <p class="slide_item_style1">Step 1: Set the box sized ~20 \(Å^{3}\) with resolution of 1Å to 0.5Å</p>
                <p class="slide_item_style1">Step 2: Align the box to the geometric center of ligand</p>
                <p class="slide_item_style1">Step 3: Compute the time-serie of closest-atom-pairs distances </p>
				<p class="slide_item_style1">Step 4: For each representative frames, compute the panelty to the mean distance</p>
				<p class="slide_item_style1">Step 5: Label those frames by \(L = K_{i/d} \times p\)</p>
				<p class="slide_item_style1">Step 6: Store the feature vectors/labels to database as training dataset</p>
            </div>
			<div class="image-style1">
				<img src="/Augment_current_methods.jpg" style="height:90% !important;">
				<p class="content_subtitle">Fig. Augment of binding affinity data from representative frames of trajectories</p>
			</div>

        </section>

		<section data-state="slide_PackageArchetecture2">
			<p class="slide-title">Protein dynamics landscape re-construction</p>
			<div class="gallery" style="top:30% !important;">
				<figure class="gallery-item PackageArchetecture image-gray" >
					<img id="PackageArchetecture_fig4" src="/Step2_1_Image_pocket.png">
					<figcaption for="PackageArchetecture_fig4">Fig1: An example binding pose to predict</figcaption>
				</figure>
				<figure class="gallery-item PackageArchetecture image-gray" >
					<img id="PackageArchetecture_fig5" src="/Step2_2_MBlock_retrieval.jpg">
					<figcaption for="PackageArchetecture_fig5">Fig2: Binding pocket extraction, "molecule block" retrieval and feature reassembly</figcaption>
				</figure>
				<figure class="gallery-item PackageArchetecture image-gray gallery-item_style4" style="height: auto !important; width: 30% !important; ">
					<img id="PackageArchetecture_fig6" style="height: 100% !important; width: 100%" src="/Step_3DCNN_prediction.png">
					<figcaption>Fig3: Affinity prediction </figcaption>
				</figure>
			</div>
		</section>

		<section data-state="slide_current_study">
            <p class="slide-title">Requirements for the dynamics landscape re-construction</p>
            <div class="slide_content_style1">
				<p class="slide_item_style1">++++++++++++++++++++++++++++++++++++++++++++++++++</p>

<!--                <p class="slide_item_style1">Robust </p>-->
				<p class="slide_item_style1">Proper database structure to store the molecule blocks and their features </p>
				<p class="slide_item_style1">Align the molecule blocks to a correct orientation (Transformation matrix) </p>
				<p class="slide_item_style1">++++++++++++++++++++++++++++++++++++++++++++++++++</p>
            </div>
            <p class="reference_style">This is a template reference.</p>
        </section>

		<section data-state="slide_PocketReassembleDetails">
			<p class="slide-title">Pocket reassembly workflow</p>
			<div class="slide_content_style1">
				<p class="slide_item_style1">1. Extract the binding site from the protein-ligand interface and establish its corresponding mesh grid </p>
				<p class="slide_item_style1">2. Sample sub-blocks within the bounding box and retrieve features from feature database  </p>
				<p class="slide_item_style1">3. Retain sub-blocks with similarity scores below a specific threshold </p>
				<p class="slide_item_style1">4. Obtain the transformation matrix through geometric alignment </p>
				<p class="slide_item_style1">5. Apply the transformation matrix to the sub-block feature and align to the target structure</p>
			</div>
			<div class="image-style1">
				<img id="img_pocket_assemble" src="/Step2_2_MBlock_retrieval.jpg" style="width: 100%; ">
				<p class="content_subtitle">Fig1. Illustrating the process of converting a static docked pose into features suitable for training. </p>
			</div>
		</section>



		<section data-state="slide_ICPRegistration">
			<p class="slide-title">Transformation matrix generation</p>
			<div class="slide_content_style1">
				<p class="slide_item_style1">Iterative closest point (ICP) is a widely-used method for aligning two sets of points or point clouds</p>
				<p class="slide_item_style1">By inputting a target point set and a source point cloud, the output is a refined transformation matrix that aligns these two point clouds</p>
				<p class="slide_item_style1">Two main steps are iterated during point cloud registration: </p>
				<p class="slide_item_style1" style="padding-left: 20px; ">1. Find correspondence set \(\kappa = \{(p,q)\}\) from target points \(P\), and source point cloud \(Q\) </p>
				<p class="slide_item_style1" style="padding-left: 20px; ">2. Update the transformation matrix by minimizing an objective function. </p>
				<p class="slide_item_style1">For example, the objective function of point-to-point ICP algorithm is \(E(T) = \sum_{(p,q)\in\kappa}{\left\|p-Tq \right\|^2}\) </p>
			</div>

			<div class="image-style1">
				<img  style="height:80%  !important;; width: auto !important; height:auto" src="https://camo.githubusercontent.com/f28d342e5dc26c660ba6184a1265fd55cf69607e2ea4cadb11919a2d8ef63491/68747470733a2f2f6361732d61737369676e6d656e742e72656164746865646f63732e696f2f656e2f6c61746573742f5f696d616765732f6963705f616e696d6174696f6e2e676966">
				<p class="content_subtitle">Fig. A visual demonstration of how the ICP algorithm aligns two point clouds</p>
			</div>

			<p class="reference_style">Besl, Paul J., and Neil D. McKay. "Method for registration of 3-D shapes." Sensor fusion IV: control paradigms and data structures. Vol. 1611. Spie, 1992.<br>https://github.com/yassram/iterative-closest-point</p>
		</section>

		<section data-state="slide_">
            <p class="slide-title">Network architecture</p>
            <div class="slide_content_style1">
				<p class="highlight_style1">General-purpose network architecture</p>
<!--                <p class="slide_item_style1">ImageNet: First </p>-->
                <p class="slide_item_style1">ResNet: Solved the vanishing gradient problem enabling very deep network structure</p>
				<p class="slide_item_style1">DenseNet: improved gradient flow, feature reuse and network efficiency</p>
                <p class="highlight_style1">Other network architecture</p>
            </div>
			<div class="image-style1">
				<img src="/DenseNet_prediction_method.jpeg" style="width:100% !important;" alt="">
				<p class="content_subtitle">Fig. DenseNet architecture</p>
				<img src="/RoseNet_prediction_method.jpeg" style="width:100% !important;">
				<p class="content_subtitle">Fig. RosENet architecture</p>
			</div>
            <p class="reference_style">
<!--				He, Kaiming, et al. "Deep residual learning for image recognition." Proceedings of the IEEE conference on computer vision and pattern recognition. 2016.<br>-->
<!--				Huang, Gao, et al. "Densely connected convolutional networks." Proceedings of the IEEE conference on computer vision and pattern recognition. 2017.<br>-->
				Imrie, Fergus, et al. "Protein family-specific models using deep neural networks and transfer learning improve virtual screening and highlight the need for more data." Journal of chemical information and modeling 58.11 (2018): 2319-2330.<br>
				Hassan-Harrirou, Hussein, Ce Zhang, and Thomas Lemmin. "RosENet: improving binding affinity prediction by leveraging molecular mechanics energies with an ensemble of 3D convolutional neural networks." Journal of chemical information and modeling 60.6 (2020): 2791-2802.<br>

			</p>
        </section>



		<section data-state="slide_KeyChildModule">
			<p class="slide-title">Development of key sub-systems</p>
			<div class="slide_content_style1">
				<p class="slide_item_style1"><span style="color:#285430; font-weight: bold">Training material:</span> Trajectories of complexes selected from PDBBind </p>
				<p class="slide_item_style1"><span style="color:#285430; font-weight: bold">Trajectory loader:</span> Automation of trajectory array</p>
				<p class="slide_item_style1"><span style="color:#285430; font-weight: bold">Molecule-block generator:</span> Identification of sub-block patterns</p>
				<p class="slide_item_style1"><span style="color:#285430; font-weight: bold">Featurizer:</span> Transformation of raw trajectories into feature vectors</p>
				<p class="slide_item_style1"><span style="color:#C58940; font-weight: bold">Input structure processor:</span> Feature retrieval and pocket reassembly</p>
				<p class="slide_item_style1"><span style="font-weight: bold">Database depositor:</span> Feature storage, retrieval and comparison</p>
				<p class="slide_item_style1" style="padding-left: 40px"><span style="color:#285430; font-weight: bold">Temporary solution:</span> HDF (Hierarchical Data Format) file</p>
				<p class="slide_item_style1"><span style="font-weight: bold">Neural network:</span> Prediction of the binding affinity</p>
			</div>
			<div class="image-style1">
				<figure class="gallery-item gallery-item_style2" style="width: 100% !important;">
					<img id="img_childmodules" src="/Overall_workflow.jpg" style="width: 100% !important; height: auto; ">
					<figcaption class="content_subtitle" for="img_childmodules">Fig1. Information flow of trajectory features and the organization of corresponding sub-systems</figcaption>
				</figure>
			</div>
		</section>

		<section data-state="slide_FutureWork">
			<p class="slide-title">Future Work</p>
			<div class="slide_content_style1">
				<p class="slide_item_style1">1. Apply the dynamics related features to some existing machine learning model</p>
				<p class="slide_item_style1">2. Augment the affinity data and re-train to some existing machine learning model</p>
				<p class="slide_item_style1">3. Build a feature database for molecule blocks (16 examples in Stage1)</p>
				<p class="slide_item_style1">4. Develop an efficient algorithm for aligning the target molecule block with retrieved sub-blocks</p>
				<p class="slide_item_style1">5. Create additional features for feature generation </p>
<!--				<p class="slide_item_style1">6. Train a voxel-based machine learning model for binding affinity prediction</p>-->
			</div>

			<div style="position: absolute; top:20%; left:50%; width:450px !important; height: 450px !important">
				<div id="final_ply_display" style="width: 100%; height: 100%"> </div>
				<p class="content_subtitle">Stage1: 3D visualization of 16 example molecule blocks</p>
			</div>
		</section>


        <section data-state="Page_Acknowledgement">
            <p class="slide-title">Acknowledgement</p>
            <ul class="slide_content_style1">
                <li>Amedeo Caflisch</li>
                <li>Andreas Vitalis</li>
				<p class="highlight_style1" style="margin-left: -20px !important;">ACGui Developers: </p>
				<li>Fabian Radler</li>
				<li>Cassiano Langini</li>
				<p class="highlight_style1" style="margin-left: -20px !important;">All the members in Caflisch group</p>
            </ul>
<!--            <div class="slide_content_style1" style="width:50%">-->
<!--            </div>-->
            <div class="image-style1" style="top:10% !important;">
                <img id="img_group"  src="/Group_photo.jpg" style="width: 100%; height:auto">
				<img id="img_group2"  src="/Group_photo2.png" style="width: 100%; height:auto">

            </div>

        </section>

        <!--<section data-state="slide_">-->
        <!--    <p class="slide-title">This is a Template Slide for Demonstration</p>-->
        <!--    <div class="slide_content_style1">-->
        <!--        <p>This is a Template Main Context1</p>-->
        <!--        <p>This is a Template Main Context2</p>-->
        <!--        <p>This is a Template Main Context3</p>-->
        <!--    </div>-->
        <!--    <p class="reference_style">This is a template reference.</p>-->
        <!--</section>-->

    </div>
</div>

<script>
    // Define the function to load ply file
    async function getGithubContents(url){
        // Fetch file from Github API
        ret = await fetch(url, {headers: github_auth});
        data = await ret.json();
        if (data.hasOwnProperty("content") && data.content.length > 0){
            console.log("Download file from github: route 1", url);
            return data.content
        } else if (data.hasOwnProperty("git_url")){
            console.log("Download file from github: route 2", data.git_url);
            ret_blob = await fetch(data.git_url, {headers: github_auth});
            data2 = await ret_blob.json();
            return data2.content
        } else if (data.hasOwnProperty("sha")){
            const blob_url =  url.replace(/contents.*/, "git/blobs")+"/"+data.sha;
            console.log("Download file from github: route 3", blob_url);
            ret_blob = await fetch(blob_url, {headers: github_auth});
            data2 = await ret_blob.json();
            return data2.content
        }
    }

    async function loadImageBase64(fileurl) {
        // Load image from URL and return base64 encoded image
        try {
            const data = await getGithubContents(fileurl);
            let dataUriPrefix;
            let format = fileurl.split('/').pop().split('.').pop();
            if (format == 'png') {
                dataUriPrefix = 'data:image/png;base64,';
            } else if (format == 'jpeg' || format == 'jpg') {
                dataUriPrefix = 'data:image/jpeg;base64,';
            } else if (format == 'gif') {
                dataUriPrefix = 'data:image/gif;base64,';
            }
            return dataUriPrefix + data
        } catch (error) {
            console.error('An error occurred while fetching the file:', error);
        }
    }

    async function setupImage(image, figurl){
		var img;
		// Check if image is an HTMLElement (like what's returned by document.getElementById)
		if (image instanceof HTMLElement) {
			img = image;
		} else if (typeof image === 'string') {
			// If it's not, assume it's an id
			img = document.getElementById(image);
			if (img == null) {
				console.log("No such image id: ", image, " in the slide.")
				return;
			}
		}
		if (figurl.startsWith("data")){
			// Base64 as input
			img.src = figurl;
		} else if (figurl.startsWith("http")) {
			// URL as input
			const fig_content = await loadImageBase64(figurl);
			img.src = fig_content;
		} else {
			// Actual file in the root folder as input
			img.src = figurl;
		}
    }


	async function getImagesFromRepo() {
		try {
			// Get the contents of the repo
			let response = await fetch(repo_url, {headers: github_auth});
			let data = await response.json();
			// Iterate over each file in the repo
			for (let file of data) {
				// Check if the file is an image
				if (file.name.endsWith('.png') || file.name.endsWith('.jpg') || file.name.endsWith('.jpeg') || file.name.endsWith('.gif')) {
					// Log the download URL of the image
					filename = file.name.split('?')[0].split("/")[file.name.split('?')[0].split("/").length-1];
					FIGURES[filename] = await loadImageBase64(repo_url + filename);
				}
			}
		} catch (error) {
			console.error("An error occurred:", error);
		}
	}


    function loadPLYMesh(plycontent, scene, camera, light) {
        // Load PLY file from base64 encoded string and return mesh
        const loader = new PLYLoader();
        const geometry = loader.parse(plycontent);
        geometry.computeVertexNormals();
        // const material = new THREE.MeshStandardMaterial({ color: 0x89aa97, flatShading: true });
        const material = new THREE.MeshStandardMaterial({vertexColors: true, flatShading: true});
        const mesh = new THREE.Mesh(geometry, material);
        geometry.computeBoundingBox();
        const boundingBox = geometry.boundingBox;
        const center = boundingBox.getCenter(new THREE.Vector3());
        mesh.position.set(-center.x, -center.y, -center.z);
        mesh.onBeforeRender = function (renderer, scene, camera) {
            light.position.copy(camera.position);
        };
        return mesh
    }

    async function addPLYtoStage(fileurl, scene, renderer, camera, light, offsets){
        const plycontent = atob(await getGithubContents(fileurl));
        var themesh = loadPLYMesh(plycontent, scene, camera, light);
        themesh.geometry.computeBoundingBox();
        const boundingBox = themesh.geometry.boundingBox;
        const center = boundingBox.getCenter(new THREE.Vector3());
        themesh.position.set(-center.x + offsets[0], -center.y + offsets[1], -center.z +offsets[2]);
        // mesh.position.set(position[0], position[1], position[2]);
        scene.add(themesh);
        return [scene, renderer, camera, light]
    }

    async function initPLYObject(divid, fileurl){
        // Initialize the scene with a ply object
        const THREE = window.THREE;
        const OrbitControls = window.OrbitControls ;
        console.log("Adding Ply object")
        // Setup for Renderer
        const renderer = new THREE.WebGLRenderer();
        var camera
        if (divid.length > 0){
            var container = document.getElementById(divid);
            console.log("using divid", divid, "Width", container.clientWidth, "Height: ", container.clientHeight)
            renderer.setSize(container.clientWidth, container.clientHeight);
            container.appendChild(renderer.domElement);
            const aspectRatio = container.clientWidth / container.clientHeight;
            camera = new THREE.PerspectiveCamera(75, aspectRatio, 0.1, 1000);
            camera.position.z = 5;
        } else {
            renderer.setSize(window.innerWidth, window.innerHeight);
            document.body.appendChild(renderer.domElement);
            camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);
            camera.position.z = 5;
        }
        // Setup for the Scene, Background color, and light
        const scene = new THREE.Scene();
        renderer.setClearColor("#"+scene_bgcolor);
        const ambientLight = new THREE.AmbientLight(0xffffff, 0.5); // 0.5 intensity
        scene.add(ambientLight);
        const light = new THREE.DirectionalLight(0xffffff, 1, 0);
        light.position.set(10, 10, 10);
        scene.add(light);

        // Add Orbit controler
        const controls = new OrbitControls(camera, renderer.domElement);

        // Convert the content from base 64 to string
        console.log("Loading the plyfile", fileurl)
        const plycontent = atob(await getGithubContents(fileurl));
        mesh = loadPLYMesh(plycontent, scene, camera, light);

        scene.add(mesh);
        camera.position.set(0, 0, 20);
        camera.near = 0.1;
        camera.far = 1000;
        camera.updateProjectionMatrix();
        return [scene, renderer, camera, light]
    }
	//////////// A Typical Animation Function ////////////
	// function animate() {
	//     requestAnimationFrame(animate);
	//     renderer.render(scene, camera);
	// }
	// console.log("Do the animation")
	// animate();
	/////////////////////////////////////////////////////

    async function init3DMolObject(divid, fileurl){
        // Initialize the scene with a 3Dmol object
        var container = document.getElementById(divid);
        var width = container.clientWidth;
        var height = container.clientHeight;
        var viewer = $3Dmol.createViewer(divid);
        let format = fileurl.split("/").pop().split(".").pop();
        console.log("Adding 3D molObj: Reading the file as ", format)

        const mol_string = atob(await getGithubContents(fileurl))
        viewer.addModel(mol_string, format);
        viewer.setStyle({}, { stick: {} });
        viewer.setBackgroundColor("#"+scene_bgcolor)
        // Zoom to fit the molecule in the viewer and Render the molecule
        viewer.zoomTo();
        viewer.render();
        // Set the canvas to relative position
        reset_canvas(divid, viewer)
        return viewer
    }

    function linspace(start, end, num) {
        // Numpy-like linspace function
        const step = (end - start) / (num - 1);
        const result = new Array(num);
        for (let i = 0; i < num; i++) {
            result[i] = start + i * step;
        }
        return result;
    }

    function renderGridPoints(viewer, center, lengths, dims) {
        // Render to grid based on three key parameters
        const sphereRadius = 0.1;
        const sphereColor = 0xff0000;
        xs = linspace(center[0]-lengths[0]/2, center[0]+lengths[0]/2, dims[0]);
        ys = linspace(center[1]-lengths[1]/2, center[1]+lengths[1]/2, dims[1]);
        zs = linspace(center[2]-lengths[2]/2, center[2]+lengths[2]/2, dims[2]);
        var newshape = viewer.addShape({color: sphereColor})
        for (let x = 0; x < xs.length; x++) {
            for (let y = 0; y < ys.length; y++) {
                for (let z = 0; z < zs.length; z++) {
                    //combinedShape.addSphere({ center: { x: xs[x], y: ys[y], z: zs[z] }, radius: sphereRadius, color: sphereColor });
                    newshape.addSphere({ center: { x: xs[x], y: ys[y], z: zs[z] }, radius: sphereRadius});
                }
            }
        }
        viewer.zoomTo();
        viewer.render();
    }
    function reset_canvas(parent_div, viewer){
        // The canvas size is reset for the 3Dmol viewer if you switch slides
        // Reset the canvas size when you go back to the slide that contains the 3Dmol viewer
        var container = document.getElementById(parent_div);
        // var width = container.clientWidth;
        var width = container.offsetWidth;
        var height = container.clientHeight;
        console.log("Set the width/height of the canvas: ",parent_div, "height/width:", height, width)
        viewer.setWidth(width);
        viewer.setHeight(height);
        viewer.render();
        // $("#"+parent_div+" canvas").css({"position": "relative", "width":"100%", "height": "100%"})
    }

    async function renderSymbol(obj_list) {
        if (! window.SetIcon) {
            scene_info = initPLYObject("symbol_fig", repo_url+"symbol_mesh.ply").then(function(ret){

                scene_info = addPLYtoStage(repo_url+"symbol_surface.ply", ret[0], ret[1],ret[2], ret[3], [0,0,0]).then(function (ret){
                    var scene = ret[0]
                    var renderer = ret[1]
                    var camera = ret[2]
					let thecenter = [0,0,0]
					let mesh_count = 0
					scene.traverse(function(meshobject){
						if (meshobject instanceof THREE.Mesh) {
							tmpcenter = meshobject.geometry.boundingBox.getCenter(new THREE.Vector3());
							thecenter[0] += tmpcenter.x
							thecenter[1] += tmpcenter.y
							thecenter[2] += tmpcenter.z
							mesh_count += 1
						}
					})
					thecenter= thecenter.map(item => item/mesh_count);
					console.log("The center is ==>: ", thecenter)


					let counter=0
					scene.traverse(function(meshobject){
						if (meshobject instanceof THREE.Mesh) {
							centerx = meshobject.position
							// centerx = meshobject.geometry.boundingBox.getCenter(new THREE.Vector3());
							console.log("The center is before translate: ", centerx)
							meshobject.translateX(thecenter[0])
							meshobject.translateY(thecenter[1])
							meshobject.translateZ(thecenter[2])
							meshobject.geometry.computeBoundingBox();
							centerx = meshobject.position
							console.log("The center is after translate: ", centerx)
							// camera.position.set(meshobject.position.x, meshobject.position.y, meshobject.position.z+15);
							// camera.lookAt(meshobject.position)
							// camera.updateProjectionMatrix()
							// counter += 1;
						}
					})
					scene.traverse(function(meshobject){
						if (meshobject instanceof THREE.Mesh) {
							console.log("====>", meshobject.position.x, meshobject.position.y, meshobject.position.z)
							// meshobject.position.x += thecenter.x;
							// meshobject.position.y += thecenter.y;
							// meshobject.position.z += thecenter.z;
							console.log("====>", meshobject.position.x, meshobject.position.y, meshobject.position.z)
							thecenter = meshobject.geometry.boundingBox.getCenter(new THREE.Vector3());
							console.log("The center is: ", thecenter)
							console.log(meshobject.rotation)
						}
					})

					// camera.position.set(thecenter.x, thecenter.y, thecenter.z+5);
					// camera.position.set(0, 0, 20);
					// camera.lookAt(0,0,0);
					// camera.lookAt(thecenter.x, thecenter.y, thecenter.z);


                    function animate() {
                        requestAnimationFrame(animate);
                        const time = (performance.now() * 0.0005) % 3 + 0.5;
						let c = 0;
                        scene.traverse(function(meshobject) {
							if (meshobject instanceof THREE.Mesh) {
								meshobject.rotation.z = 0.05;
								meshobject.rotation.y += time*0.004;

								if (c==1){
									meshobject.material.color = new THREE.Color(0x71EFA3);
									meshobject.material.transparent = true;
									meshobject.material.opacity = 0.75;
									// console.log("====>", meshobject.position.x, meshobject.position.y, meshobject.position.z)
								}
								c+=1
							}
                        });
                        renderer.render(scene, camera);
                    }
                    animate()
                });
            });
            window.SetIcon = true
        }
    }
	function getElemName(element){
		if (typeof element === 'string' || element instanceof String){
			let elem = document.getElementById(element);
			// let src_str = elem.src.split();
			return elem.src.split("/")[elem.src.split("/").length-1]
		} else if (element instanceof HTMLElement){
			let elem = element;
			return elem.src.split("/")[elem.src.split("/").length-1]
		}
	}


    /////////////////////////////////////////////
    ////////// Set up global variables //////////
    /////////////////////////////////////////////
    const scene_bgcolor = "FFF9DE";
    const github_auth = {
        Authorization: "Bearer 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",
        Accept: "application/vnd.github+object",
    };

    const repo_url = "https://api.github.com/repos/miemiemmmm/GM_28Jun2023/contents/";

    // Set up the background image of the first greeting page
	var greetingimage_elem = document.getElementById("greeting_bgimage")
    setupImage(greetingimage_elem, getElemName(greetingimage_elem))

    var uzh_logo_e_pos_web_main
    var image_section_break

    (async ()=>{
        // Get UZH logo, presentation symbol and set up the logo for the first page
        uzh_logo_e_pos_web_main = await loadImageBase64(repo_url+"uzh_logo_e_pos_web_main.jpg");
        var imgdiv = document.createElement('img');
        imgdiv.classList.add('uzh_logo');
        imgdiv.src = uzh_logo_e_pos_web_main;
        document.body.appendChild(imgdiv);

        image_section_break= await loadImageBase64(repo_url+"section_break.png");
        // image_symbol = await loadImageBase64(repo_url+"symbol.png");
        // image1 = await loadImageBase64(repo_url+"im1.png");
        // image2 = await loadImageBase64(repo_url+"im2.png");
        // image3 = await loadImageBase64(repo_url+"im3.png");
    })()

	var PRELOAD_FIGURES = true
	var FIGURES = {}
	if (PRELOAD_FIGURES == true){
		getImagesFromRepo()
	}

    /////////////////////////////////////////////
    ///// Initialize the reveal.js framework ////
    /////////////////////////////////////////////
    Reveal.initialize({
        // Set the theme to white
        theme: 'white',
        // Set the transition style to slide
        transition: 'convex',
    });

    Reveal.addEventListener('slidechanged', function(event) {
        if (event.currentSlide && event.currentSlide.getAttribute('data-state') == 'slide_common_methods') {
            if ( !window.hasOwnProperty("voxel_box_set") ) {
                init3DMolObject("slide_RefPDBAndBox", repo_url+"C209CsDJQucZ_Protein2.pdb")
                    .then(viewer=>{
                        // Set styles for the protein structure
                        viewer.setStyle({}, { cartoon:{color: "gray"} } );
                        var ligandSelection = {resn: 'LIG',  byres:true, expand:5};
                        viewer.setStyle(ligandSelection, {stick: {colorscheme:"greenCarbon"}, cartoon: {}});
                        // Add Grid points
                        const center = [22.0947246 , 36.49708133, 21.81810805];
                        const ls = [24, 24, 24];
                        const dims = [12, 12, 12];
                        renderGridPoints(viewer, center, ls, dims);
                        viewer.addBox({center:{x:center[0], y:center[1] ,z:center[2]},
                            dimensions: {w:ls[0], h:ls[1], d:ls[2]},
                            color:'#adf7d1',
                            opacity:0.65
                        })
                        const centers = [
                            [34.88775634765625, 38.64504623413086, 18.944740295410156], [30.713611602783203, 42.00475311279297, 19.096406936645508], [28.294567108154297, 44.30536651611328, 17.057537078857422],
                            [27.101287841796875, 45.99188232421875, 21.745433807373047], [21.747516632080078, 46.85906219482422, 26.61472511291504], [19.334928512573242, 44.54450225830078, 35.28935623168945],
                            [16.974706649780273, 41.76900100708008, 31.347522735595703], [17.396854400634766, 37.726806640625, 27.266767501831055]
                        ]
                        const block_ls = [6,6,6]
                        for (var i=0; i < centers.length; i++){
                            viewer.addBox({center:{x:centers[i][0], y:centers[i][1] ,z:centers[i][2]},
                                dimensions: {w:block_ls[0], h:block_ls[1], d:block_ls[2]},
                                color:'#8971d0',
                                opacity:1,
                            })
                            viewer.addBox({center:{x:centers[i][0], y:centers[i][1] ,z:centers[i][2]},
                                dimensions: {w:block_ls[0]+0.5, h:block_ls[1]+0.5, d:block_ls[2]+0.5},
                                color:'black',
                                opacity:0.6
                            })
                        }
                        viewer.rotate(195, {x: 0, y: 1, z: 0});
                        viewer.render();
                        window.voxel_box_set = true;
                        window.viewer_RefPDBAndBox = viewer;
                        reset_canvas("slide_RefPDBAndBox", window.viewer_RefPDBAndBox)
                    })
            } else {
                console.log(window.viewer_RefPDBAndBox)
                window.viewer_RefPDBAndBox.render()
                reset_canvas("slide_RefPDBAndBox", window.viewer_RefPDBAndBox)
            }
        }
    })

	Reveal.addEventListener('slidechanged', function(event) {
		if (event.currentSlide && event.currentSlide.getAttribute('data-state') == 'slide_ExampleMolBlock') {
			if ( !window.hasOwnProperty("ExampleMolBlock_set") ) {
				initPLYObject("mol_block_mesh", repo_url + "example_block2.ply")
					.then(ret =>{
						const scene = ret[0];
						const renderer = ret[1];
						const camera = ret[2];
						const light = ret[3];
						function animate() {
							requestAnimationFrame(animate);
							const time = (performance.now() * 0.0005) % 3 + 0.5;
							let c = 0;
							scene.traverse(function(meshobject) {
								if (meshobject instanceof THREE.Mesh) {
									meshobject.rotation.z = 0.05;
									meshobject.rotation.y += time*0.004;

									if (c==1){
										meshobject.material.color = new THREE.Color(0x71EFA3);
										meshobject.material.transparent = true;
										meshobject.material.opacity = 0.75;
										// console.log("====>", meshobject.position.x, meshobject.position.y, meshobject.position.z)
									}
									c+=1
								}
							});
							renderer.render(scene, camera);
						}
						animate()

					})

				init3DMolObject("mol_block_pdb", repo_url + "example_block2.pdb")
					.then(viewer => {
						const centeri = [21.84767489, 44.66006607, 28.9396247 ];
						const block_ls = [8,8,8];
						viewer.setStyle({chain:'B'}, {stick: {color: 'red'}});

						viewer.addBox({center:{x:centeri[0], y:centeri[1] ,z:centeri[2]},
							dimensions: {w:block_ls[0], h:block_ls[1], d:block_ls[2]},
							color:'#8971d0',
							opacity:0.7
						})
						viewer.render();
						window.viewer_ExampleMolBlock_set = viewer;
						window.ExampleMolBlock_set = true
						// reset_canvas("mol_block_mesh", window.viewer_ExampleMolBlock_set)
					})
			}  else {
				console.log(window.viewer_ExampleMolBlock_set)
				window.viewer_ExampleMolBlock_set.render()
				reset_canvas("mol_block_pdb", window.viewer_ExampleMolBlock_set)
			}
		}
	})



	Reveal.addEventListener('slidechanged', function(event) {
		if (event.currentSlide && event.currentSlide.getAttribute('data-state') == 'slide_FutureWork') {
			if ( !window.hasOwnProperty("plyset_set") ) {
				initPLYObject("final_ply_display", repo_url + "final_plys/tmpzc7n5fhg_final.ply")
					.then(ret =>{
						const scene = ret[0];
						const renderer = ret[1];
						const camera = ret[2];
						const light = ret[3];
						var unitoffset = 12
						addPLYtoStage(repo_url + "final_plys/tmp5llzxuex_final.ply", ret[0], ret[1], ret[2], ret[3], [-unitoffset,0 ,0])
						addPLYtoStage(repo_url + "final_plys/tmp5t735ia__final.ply", ret[0], ret[1], ret[2], ret[3], [unitoffset,0 ,0])
						addPLYtoStage(repo_url + "final_plys/tmpe1peac1p_final.ply", ret[0], ret[1], ret[2], ret[3], [0, -unitoffset, 0])
						addPLYtoStage(repo_url + "final_plys/tmpezuetj0d_final.ply", ret[0], ret[1], ret[2], ret[3], [0, unitoffset, 0])

						addPLYtoStage(repo_url + "final_plys/tmp6avlixw7_final.ply", ret[0], ret[1], ret[2], ret[3], [unitoffset,-unitoffset, 0])
						addPLYtoStage(repo_url + "final_plys/tmp8q4vb64d_final.ply", ret[0], ret[1], ret[2], ret[3], [-unitoffset, unitoffset, 0])
						addPLYtoStage(repo_url + "final_plys/tmpm0cef41l_final.ply", ret[0], ret[1], ret[2], ret[3], [unitoffset, unitoffset, 0])
						addPLYtoStage(repo_url + "final_plys/tmpq6nlb_fz_final.ply", ret[0], ret[1], ret[2], ret[3], [-unitoffset, -unitoffset, 0])

						addPLYtoStage(repo_url + "final_plys/tmpmhgc81ig_final.ply", ret[0], ret[1], ret[2], ret[3], [2*unitoffset, 0, 0])
						addPLYtoStage(repo_url + "final_plys/tmp2a67037l_final.ply", ret[0], ret[1], ret[2], ret[3], [0, 2*unitoffset , 0])
						addPLYtoStage(repo_url + "final_plys/tmpwwds3dqa_final.ply", ret[0], ret[1], ret[2], ret[3], [unitoffset, 2*unitoffset, 0])
						addPLYtoStage(repo_url + "final_plys/tmpr4oid3gj_final.ply", ret[0], ret[1], ret[2], ret[3], [2*unitoffset, unitoffset, 0])
						addPLYtoStage(repo_url + "final_plys/tmptmv1rt7k_final.ply", ret[0], ret[1], ret[2], ret[3], [2*unitoffset, -unitoffset, 0])
						addPLYtoStage(repo_url + "final_plys/tmp42l6jg8w_final.ply", ret[0], ret[1], ret[2], ret[3], [-unitoffset,2*unitoffset, 0])
						addPLYtoStage(repo_url + "final_plys/tmpq5d3h7a3_final.ply", ret[0], ret[1], ret[2], ret[3], [2*unitoffset, 2*unitoffset, 0])

						function animate() {
							requestAnimationFrame(animate);
							const time = (performance.now() * 0.0005) % 3 + 0.5;
							let c = 0;
							scene.traverse(function(meshobject) {
								if (meshobject instanceof THREE.Mesh) {
									meshobject.rotation.z = 0.05;
									meshobject.rotation.y += time*0.004;

									if (c==1){
										meshobject.material.color = new THREE.Color(0x71EFA3);
										meshobject.material.transparent = true;
										meshobject.material.opacity = 0.75;
										// console.log("====>", meshobject.position.x, meshobject.position.y, meshobject.position.z)
									}
									c+=1
								}
							});
							renderer.render(scene, camera);
						}
						animate()
					})
				window.plyset_set = true;
			}
		}
	})


    /////////////////////////////////////////////
    ////// Auxiliary and onchange functions /////
    /////////////////////////////////////////////
    Reveal.addEventListener( 'slidechanged', function( event ) {
		var images = event.currentSlide.getElementsByTagName('img');
		// Iterate over each image
		for (var i = 0; i < images.length; i++) {
			// Log the src attribute to the console
			if (images[i].src.length > 0 && images[i].src.length < 75 && ! images[i].src.includes("http")){
				let imagename = getElemName(images[i]);
						// images[i].src.split("/")[images[i].src.split("/").length-1];

				if (FIGURES.hasOwnProperty(imagename)){
					console.log("Setting image from FIGURES variable")
					images[i].src = FIGURES[imagename];
				} else {
					console.log("Setting image with filename (Download): ", imagename);
			  		setupImage(images[i], repo_url + imagename);
				}

			}
		}

        // Add the UZH logo
        var uzhLogoElement = document.querySelector( '.uzh_logo' );
        if ( uzhLogoElement ) {
            uzhLogoElement.src = uzh_logo_e_pos_web_main;
        } else {
            var imgdiv = document.createElement( 'img' );
            imgdiv.classList.add( 'uzh_logo' );
            imgdiv.src = uzh_logo_e_pos_web_main;
            document.body.appendChild( imgdiv );
        }

        // Add the footer page number
        var pageNumber = event.indexh + 1;
        var totalPages = Reveal.getTotalSlides();
        var pageString = pageNumber + '/' + totalPages;
        var pageNumberElement = document.querySelector( '.page-number' );
        if ( pageNumberElement ) {
            pageNumberElement.innerHTML = pageString;
            pageNumberElement.style.zIndex = 0
        } else {
            var pagediv = document.createElement( 'div' );
            pagediv.classList.add( 'page-number' );
            pagediv.innerHTML = pageString;
            pagediv.style.zIndex = 0
            document.body.appendChild( pagediv );
        }

        var symbol_fig = document.querySelector( '.symbol_fig' );
        if ( symbol_fig ) {
            // symbol_fig.src = image_symbol
        } else {
            var symboldiv = document.createElement( 'div' );
            symboldiv.classList.add( 'symbol_fig' );
            symboldiv.id = "symbol_fig";
            // symboldiv.src = image_symbol;
            symboldiv.style.width  = '120px';   // Set the width
            symboldiv.style.height = '120px';
            symboldiv.style.zIndex = 0
            document.body.appendChild(symboldiv)
            renderSymbol()
        }


        const viewportWidth = window.innerWidth || document.documentElement.clientWidth;
        const viewportHeight = window.innerHeight || document.documentElement.clientHeight;
        // console.log("ViewPort Width:", viewportWidth, "/ Height", viewportHeight);
        // $("#slide_container").css({"width": String(viewportWidth*0.45)+"px"})



        // setup break slide
        var found_chapterbreak = event.currentSlide.querySelector( '.chapter_break_container' );
        var found_chapterbreakimg = event.currentSlide.querySelector( '.chapter_break_container img' );
        if ( found_chapterbreak && found_chapterbreakimg.src.slice(0,4) !== "data") {
            found_chapterbreakimg.src = image_section_break
            found_chapterbreakimg.style.zIndex = -10;
            found_chapterbreakimg.style.width = '75%';
            found_chapterbreakimg.style.position = "absolute"
            found_chapterbreakimg.style.transform = 'rotate(-30deg)';
            found_chapterbreakimg.style.filter = "blur(5px)";
            found_chapterbreakimg.style.bottom = 0;
            found_chapterbreakimg.style.right = "-30%";
            found_chapterbreakimg.style.opacity = 0.2;
            var chapterbreak = document.querySelector( '.chapter_break')
            chapterbreak.style.zIndex = 999
        }
    });

    // Laser pointer function for the slides
    const laserPointer = document.querySelector('.laser-pointer');
    var usingLaser = false;
    // Enable/disable the laser pointer on holding the 'L' key (key code 76)
    document.addEventListener('keydown', (event) => {
        if (event.key == "1" && !usingLaser){
            laserPointer.style.opacity = 1;
            usingLaser=true
            $('body').css('cursor', 'none');
            laserPointer.style.left = -100+"px";
            laserPointer.style.top = -100+"px";
        } else {
            laserPointer.style.opacity = 0;
            usingLaser=false
            $('body').css('cursor', 'default');
        }
    });

    // Move the laser pointer with the mouse
    document.addEventListener('mousemove', (event) => {
        if (usingLaser) {
            laserPointer.style.left = event.clientX - laserPointer.clientWidth / 2 + 'px';
            laserPointer.style.top = event.clientY - laserPointer.clientHeight / 2 + 'px';
        }
    });

    $(".gallery-item").hover(
        function() {
            $(this).css({"z-index": 999})
        },
        function() {
            $(this).css({"z-index": 0})
        }
    );
</script>

</body>
</html>
